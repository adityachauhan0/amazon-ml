
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="My ML notes, cheatsheets, and experiments">
      
      
      
        <link rel="canonical" href="https://adityachauhan0.github.io/amazon-ml/notes/lecture4/">
      
      
        <link rel="prev" href="../lecture3/">
      
      
        <link rel="next" href="../../cheatsheets/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.17">
    
    
      
        <title>Unsupervised Learning - Machine Learning Notes</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="pink">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#unsupervised-learning" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Machine Learning Notes" class="md-header__button md-logo" aria-label="Machine Learning Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Machine Learning Notes
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Unsupervised Learning
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="pink"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="pink"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="pink"  aria-label="Switch to high contrast"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to high contrast" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 20c-2.21 0-4.21-.9-5.66-2.34L17.66 6.34A8.01 8.01 0 0 1 20 12a8 8 0 0 1-8 8M6 8h2V6h1.5v2h2v1.5h-2v2H8v-2H6M12 2A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10A10 10 0 0 0 12 2m0 14h5v-1.5h-5z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/adityachauhan0/amazon-ml" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    adityachauhan0/amazon-ml
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../lecture3/" class="md-tabs__link">
          
  
  
    
  
  Notes

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../cheatsheets/" class="md-tabs__link">
        
  
  
    
  
  Cheatsheets

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Machine Learning Notes" class="md-nav__button md-logo" aria-label="Machine Learning Notes" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Machine Learning Notes
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/adityachauhan0/amazon-ml" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    adityachauhan0/amazon-ml
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Notes
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lecture3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Dimensionality Reduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Unsupervised Learning
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Unsupervised Learning
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#types-of-unsupervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Types of Unsupervised Learning
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dimensionality-reduction" class="md-nav__link">
    <span class="md-ellipsis">
      Dimensionality Reduction
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Dimensionality Reduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mathematical-view" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical View
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pca-example-concept" class="md-nav__link">
    <span class="md-ellipsis">
      PCA Example (concept)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pca-minimal-python" class="md-nav__link">
    <span class="md-ellipsis">
      PCA: Minimal Python
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#clustering" class="md-nav__link">
    <span class="md-ellipsis">
      Clustering
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Clustering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#types-of-clustering-models" class="md-nav__link">
    <span class="md-ellipsis">
      Types of Clustering Models
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#clustering-minimal-python-snippets" class="md-nav__link">
    <span class="md-ellipsis">
      Clustering: Minimal Python Snippets
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k-means-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      K-means Clustering
    </span>
  </a>
  
    <nav class="md-nav" aria-label="K-means Clustering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#objective" class="md-nav__link">
    <span class="md-ellipsis">
      Objective
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-means-algorithm" class="md-nav__link">
    <span class="md-ellipsis">
      K-means Algorithm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-means-minimal-python" class="md-nav__link">
    <span class="md-ellipsis">
      K-means: Minimal Python
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-means-initialization-sketch" class="md-nav__link">
    <span class="md-ellipsis">
      K-means++ Initialization (sketch)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sample-iteration-illustrated" class="md-nav__link">
    <span class="md-ellipsis">
      Sample Iteration (Illustrated)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Sample Iteration (Illustrated)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#0-inputs-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      0) Inputs &amp; Initialization
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1-assignment-step-e-step-analogue" class="md-nav__link">
    <span class="md-ellipsis">
      1) Assignment Step (E-step analogue)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-update-step-m-step-analogue" class="md-nav__link">
    <span class="md-ellipsis">
      2) Update Step (M-step analogue)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-convergence-check" class="md-nav__link">
    <span class="md-ellipsis">
      3) Convergence Check
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-full-mini-run-example-t0-t2" class="md-nav__link">
    <span class="md-ellipsis">
      4) Full Mini-Run Example (t=0 → t=2)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#applications-of-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      Applications of Clustering
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#image-compression-using-k-means" class="md-nav__link">
    <span class="md-ellipsis">
      Image Compression using K-means
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Image Compression using K-means">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#minimal-python-for-color-quantization" class="md-nav__link">
    <span class="md-ellipsis">
      Minimal Python for Color Quantization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cheatsheets/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cheatsheets
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/adityachauhan0/amazon-ml/edit/main/docs/notes/lecture4.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/adityachauhan0/amazon-ml/raw/main/docs/notes/lecture4.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="unsupervised-learning">Unsupervised Learning<a class="headerlink" href="#unsupervised-learning" title="Permanent link">&para;</a></h1>
<p>Unsupervised learning is a type of machine learning where the model is trained on <strong>unlabeled</strong> data. The goal is to discover hidden patterns, structures, or representations in the data without explicit supervision.</p>
<hr />
<h2 id="types-of-unsupervised-learning">Types of Unsupervised Learning<a class="headerlink" href="#types-of-unsupervised-learning" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p><strong>Dimensionality Reduction</strong><br />
   Transformation of data from high-dimensional vector space to low-dimensional space without losing important information.</p>
</li>
<li>
<p><strong>Clustering</strong><br />
   Grouping input data points into clusters based on similarity.</p>
</li>
<li>
<p><strong>Generative Modelling</strong><br />
   Modeling the underlying data distribution and generating new data points from it.</p>
</li>
<li>
<p><strong>Representation Learning</strong><br />
   Learning low-dimensional semantic representations of data.</p>
</li>
</ol>
<hr />
<h2 id="dimensionality-reduction">Dimensionality Reduction<a class="headerlink" href="#dimensionality-reduction" title="Permanent link">&para;</a></h2>
<p>Dimensionality reduction reduces the number of features while retaining essential information.</p>
<ul>
<li>Common methods: <strong>PCA</strong>, <strong>t‑SNE</strong>, <strong>Matrix factorization (NMF/SVD)</strong>, <strong>Autoencoders</strong></li>
<li><strong>PCA (Principal Component Analysis):</strong><br />
  Projects data onto new axes that capture maximum variance.</li>
<li>In PCA, the projection axes correspond to the <strong>eigenvectors of the covariance matrix</strong>.</li>
</ul>
<h3 id="mathematical-view">Mathematical View<a class="headerlink" href="#mathematical-view" title="Permanent link">&para;</a></h3>
<p>Given zero-mean data matrix <span class="arithmatex">\(X\in\mathbb{R}^{n\times d}\)</span>:</p>
<ol>
<li>Center the data.</li>
<li>Compute covariance matrix:
   $$ C = \frac{1}{n} X^T X $$</li>
<li>Compute eigenvalues and eigenvectors of <span class="arithmatex">\(C\)</span>.</li>
<li>Project data onto top-<span class="arithmatex">\(k\)</span> eigenvectors.</li>
</ol>
<h3 id="pca-example-concept">PCA Example (concept)<a class="headerlink" href="#pca-example-concept" title="Permanent link">&para;</a></h3>
<pre class="mermaid"><code>%%{init: {'theme': 'default'}}%%
flowchart LR
    A[Raw 2D Data Distribution] --&gt; B[Projection on Primary Eigenvector]
    A --&gt; C[Projection on Secondary Eigenvector]</code></pre>
<h3 id="pca-minimal-python">PCA: Minimal Python<a class="headerlink" href="#pca-minimal-python" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.decomposition</span><span class="w"> </span><span class="kn">import</span> <span class="n">PCA</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a><span class="n">X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># center</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="n">Z</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Explained variance ratio:&quot;</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a><span class="c1"># Z can be plotted or used downstream (e.g., clustering)</span>
</span></code></pre></div>
<hr />
<h2 id="clustering">Clustering<a class="headerlink" href="#clustering" title="Permanent link">&para;</a></h2>
<p><strong>Definition:</strong> Clustering is the task of grouping a set of objects so that objects within the same group are more similar to each other than to objects in other groups.</p>
<h3 id="types-of-clustering-models">Types of Clustering Models<a class="headerlink" href="#types-of-clustering-models" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Centroid-based</strong>  </li>
<li>Clusters are represented by a central vector (centroid).  </li>
<li>Each data point belongs to the cluster with the closest centroid.  </li>
<li>
<p>Examples: <strong>K-means</strong>, <strong>K-medoids</strong>.</p>
</li>
<li>
<p><strong>Connectivity-based (Hierarchical)</strong>  </p>
</li>
<li>Builds a hierarchy of clusters based on distances.  </li>
<li>Two main strategies:  <ul>
<li><em>Agglomerative</em>: Start with each point as a cluster and merge.</li>
<li><em>Divisive</em>: Start with one big cluster and split recursively.  </li>
</ul>
</li>
<li>
<p>Produces a <strong>dendrogram</strong>.</p>
</li>
<li>
<p><strong>Graph-based</strong>  </p>
</li>
<li>Models data as a graph where nodes are data points and edges represent similarity.  </li>
<li>
<p>Partitions graph into communities using methods like <strong>spectral clustering</strong> or <strong>minimum cut</strong>.</p>
</li>
<li>
<p><strong>Distribution-based</strong>  </p>
</li>
<li>Assumes data is generated from a mixture of probability distributions.  </li>
<li>Learns parameters of distributions using methods like <strong>Expectation-Maximization (EM)</strong>.  </li>
<li>
<p>Example: <strong>Gaussian Mixture Models (GMMs)</strong>.</p>
</li>
<li>
<p><strong>Density-based</strong>  </p>
</li>
<li>Defines clusters as high-density regions separated by low-density regions.  </li>
<li>Can discover arbitrarily shaped clusters and handle noise/outliers.  </li>
<li>
<p>Examples: <strong>DBSCAN</strong>, <strong>OPTICS</strong>.</p>
</li>
<li>
<p><strong>Others</strong>  </p>
</li>
<li><strong>Grid-based</strong>: Divides space into a grid and identifies dense cells.  </li>
<li><strong>Neural network–based</strong>: e.g., Self-Organizing Maps (SOM).  </li>
<li><strong>Soft clustering</strong>: Assigns probabilities of belonging to clusters.  </li>
<li><strong>Mutual information clustering</strong>: Groups data by maximizing shared information.</li>
</ol>
<h3 id="clustering-minimal-python-snippets">Clustering: Minimal Python Snippets<a class="headerlink" href="#clustering-minimal-python-snippets" title="Permanent link">&para;</a></h3>
<p><strong>K-means / Elbow &amp; Silhouette</strong>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">silhouette_score</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="n">inertias</span><span class="p">,</span> <span class="n">silhouettes</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a><span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>    <span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>    <span class="n">labels</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>    <span class="n">inertias</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">km</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>    <span class="n">silhouettes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a><span class="n">best_k</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">silhouettes</span><span class="p">))</span>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a><span class="nb">print</span><span class="p">({</span><span class="s2">&quot;best_k_by_silhouette&quot;</span><span class="p">:</span> <span class="n">best_k</span><span class="p">})</span>
</span></code></pre></div></p>
<p><strong>Hierarchical (Agglomerative) &amp; Dendrogram</strong>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_blobs</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">scipy.cluster.hierarchy</span><span class="w"> </span><span class="kn">import</span> <span class="n">linkage</span><span class="p">,</span> <span class="n">dendrogram</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.60</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="n">Z</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;ward&quot;</span><span class="p">)</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a><span class="c1"># In a notebook, you would: dendrogram(Z); plt.show()</span>
</span></code></pre></div></p>
<p><strong>DBSCAN (density-based)</strong>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">DBSCAN</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">cluster_std</span><span class="o">=</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">),</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="n">labels</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">min_samples</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Clusters found (including -1 for noise):&quot;</span><span class="p">,</span> <span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">))</span>
</span></code></pre></div></p>
<hr />
<h2 id="k-means-clustering">K-means Clustering<a class="headerlink" href="#k-means-clustering" title="Permanent link">&para;</a></h2>
<p><strong>Definition:</strong> A method of grouping <span class="arithmatex">\(N\)</span> data points into <span class="arithmatex">\(K\)</span> clusters, where each data point belongs to the nearest cluster center based on a distance metric.</p>
<h3 id="objective">Objective<a class="headerlink" href="#objective" title="Permanent link">&para;</a></h3>
<p>Minimize the within-cluster sum of squares (WCSS):
<span class="arithmatex">\(<span class="arithmatex">\(\min_{\{C_k,\mu_k\}} \sum_{k=1}^K \sum_{x_i\in C_k} \lVert x_i-\mu_k \rVert^2\)</span>\)</span></p>
<h3 id="k-means-algorithm">K-means Algorithm<a class="headerlink" href="#k-means-algorithm" title="Permanent link">&para;</a></h3>
<ol>
<li>Choose number of clusters <span class="arithmatex">\(k\)</span>.</li>
<li>Initialize <span class="arithmatex">\(k\)</span> cluster centers (e.g., random or <strong>k-means++</strong>).</li>
<li><strong>Assign</strong> each data point to its nearest center (by chosen distance metric).</li>
<li><strong>Update</strong> each center to be the centroid: <span class="arithmatex">\(\mu_k=\frac{1}{|C_k|}\sum_{x_i\in C_k} x_i\)</span>.</li>
<li>Repeat steps 3–4 until convergence (centers stop moving or WCSS improvement <span class="arithmatex">\(&lt;\varepsilon\)</span>).</li>
</ol>
<pre class="mermaid"><code>%%{init: {'theme': 'forest'}}%%
flowchart TD
    A[Initialize k cluster centers] --&gt; B[Assign points to nearest cluster]
    B --&gt; C[Update cluster centers]
    C --&gt; D{Converged?}
    D -- No --&gt; B
    D -- Yes --&gt; E[Final Clusters]</code></pre>
<h3 id="k-means-minimal-python">K-means: Minimal Python<a class="headerlink" href="#k-means-minimal-python" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_blobs</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="n">X</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="n">labels</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="n">centers</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">cluster_centers_</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;WCSS (inertia):&quot;</span><span class="p">,</span> <span class="n">km</span><span class="o">.</span><span class="n">inertia_</span><span class="p">)</span>
</span></code></pre></div>
<h3 id="k-means-initialization-sketch">K-means++ Initialization (sketch)<a class="headerlink" href="#k-means-initialization-sketch" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="c1"># X shape: (n_samples, d)</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="n">centers</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="n">centers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">))])</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a><span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>  <span class="c1"># pick until K centers</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>    <span class="n">d2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(((</span><span class="n">X</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">centers</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>    <span class="n">probs</span> <span class="o">=</span> <span class="n">d2</span> <span class="o">/</span> <span class="n">d2</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>    <span class="n">centers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="n">probs</span><span class="p">)])</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a><span class="n">centers</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">centers</span><span class="p">)</span>
</span></code></pre></div>
<hr />
<h2 id="sample-iteration-illustrated">Sample Iteration (Illustrated)<a class="headerlink" href="#sample-iteration-illustrated" title="Permanent link">&para;</a></h2>
<p>Below is a step-by-step depiction of <strong>one complete iteration</strong> of K-means (for <span class="arithmatex">\(K=3\)</span>). Use it to understand the loop that repeats until convergence.</p>
<h3 id="0-inputs-initialization">0) Inputs &amp; Initialization<a class="headerlink" href="#0-inputs-initialization" title="Permanent link">&para;</a></h3>
<ul>
<li>Data points <span class="arithmatex">\(\{x_1,\dots,x_N\}\)</span> in <span class="arithmatex">\(\mathbb{R}^d\)</span> (unlabeled).</li>
<li>Number of clusters <span class="arithmatex">\(K\)</span>.</li>
<li>Initial centers <span class="arithmatex">\(\mu^{(0)}_1,\mu^{(0)}_2,\mu^{(0)}_3\)</span> (e.g., random or k-means++).</li>
</ul>
<pre class="mermaid"><code>%%{init: {'theme': 'default'}}%%
flowchart LR
    D[Data X: x1..xN] --&gt;|choose K| K[Set K=3]
    K --&gt; I[Init centers μ1⁽⁰⁾, μ2⁽⁰⁾, μ3⁽⁰⁾]</code></pre>
<h3 id="1-assignment-step-e-step-analogue">1) Assignment Step (E-step analogue)<a class="headerlink" href="#1-assignment-step-e-step-analogue" title="Permanent link">&para;</a></h3>
<p>For each point <span class="arithmatex">\(x_i\)</span>, choose the closest center by distance <span class="arithmatex">\(d(\cdot,\cdot)\)</span> (often Euclidean):
$$ a_i^{(t)} = \arg\min_{k\in{1,2,3}} d\big(x_i,\mu_k^{(t)}\big). $$</p>
<pre class="mermaid"><code>%%{init: {'theme': 'neutral'}}%%
flowchart TD
    subgraph Assignment at iteration t
    X1[x1] --&gt;|"d(x1, mu1^t) d(x1, mu2^t) d(x1, mu3^t)"| A1[Assign to closest]
    X2[x2] --&gt; A1
    XN[xN] --&gt; A1
    A1 --&gt; C1[C1]
    A1 --&gt; C2[C2]
    A1 --&gt; C3[C3]
    end
</code></pre>
<h3 id="2-update-step-m-step-analogue">2) Update Step (M-step analogue)<a class="headerlink" href="#2-update-step-m-step-analogue" title="Permanent link">&para;</a></h3>
<p>Recompute each center as the mean of currently assigned points:
$$ \mu_k^{(t+1)} = \frac{1}{|C_k^{(t)}|} \sum_{x_i\in C_k^{(t)}} x_i. $$</p>
<pre class="mermaid"><code>%%{init: {'theme': 'base'}}%%
flowchart LR
    C1[C₁ points] --&gt; U1[Compute μ₁⁽ᵗ⁺¹⁾]
    C2[C₂ points] --&gt; U2[Compute μ₂⁽ᵗ⁺¹⁾]
    C3[C₃ points] --&gt; U3[Compute μ₃⁽ᵗ⁺¹⁾]
    U1 --&gt; M[New centers μ⁽ᵗ⁺¹⁾]
    U2 --&gt; M
    U3 --&gt; M</code></pre>
<h3 id="3-convergence-check">3) Convergence Check<a class="headerlink" href="#3-convergence-check" title="Permanent link">&para;</a></h3>
<ul>
<li>Stop if centers move less than a tolerance <span class="arithmatex">\(\varepsilon\)</span> <strong>or</strong> max iterations reached.</li>
<li>Otherwise, set <span class="arithmatex">\(t\leftarrow t+1\)</span> and repeat Assignment &amp; Update.</li>
</ul>
<pre class="mermaid"><code>%%{init: {'theme': 'forest'}}%%
stateDiagram-v2
    [*] --&gt; Assign: Step 1
    Assign --&gt; Update: Step 2
    Update --&gt; Check: Step 3
    Check --&gt; Assign: shift(μ)&lt;ε
    Check --&gt; [*]: converged</code></pre>
<h3 id="4-full-mini-run-example-t0-t2">4) Full Mini-Run Example (t=0 → t=2)<a class="headerlink" href="#4-full-mini-run-example-t0-t2" title="Permanent link">&para;</a></h3>
<p>A compact timeline of two iterations:</p>
<pre class="mermaid"><code>%%{init: {'theme': 'neutral'}}%%
sequenceDiagram
    participant X as Data X
    participant M0 as μ⁽⁰⁾ (init)
    participant A1 as Assign (t=0)
    participant U1 as Update (t=0→1)
    participant M1 as μ⁽¹⁾
    participant A2 as Assign (t=1)
    participant U2 as Update (t=1→2)
    participant M2 as μ⁽²⁾

    X-&gt;&gt;M0: Choose K &amp; initialize centers
    M0-&gt;&gt;A1: Use μ⁽⁰⁾ to assign each xᵢ
    A1-&gt;&gt;U1: Build clusters C₁,C₂,C₃
    U1-&gt;&gt;M1: Compute new centers μ⁽¹⁾
    M1-&gt;&gt;A2: Re-assign with μ⁽¹⁾
    A2-&gt;&gt;U2: Update centers again → μ⁽²⁾
    U2--&gt;&gt;M2: Check convergence</code></pre>
<blockquote>
<p><strong>Notes</strong>
- Distance choice matters (Euclidean vs cosine). Scale features or standardize when needed.
- Random init can trap in local minima → prefer <strong>k-means++</strong> and multiple restarts.
- Use inertia (WCSS) or silhouette score to pick <span class="arithmatex">\(K\)</span>.</p>
</blockquote>
<hr />
<h2 id="applications-of-clustering">Applications of Clustering<a class="headerlink" href="#applications-of-clustering" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Exploratory Data Analysis</strong></li>
<li><strong>Dimensionality Reduction + Clustering</strong></li>
<li><strong>Feature Extraction + Clustering</strong></li>
<li><strong>Lossy Image Compression</strong></li>
<li><strong>Post-training Model Analysis</strong></li>
</ul>
<hr />
<h2 id="image-compression-using-k-means">Image Compression using K-means<a class="headerlink" href="#image-compression-using-k-means" title="Permanent link">&para;</a></h2>
<ul>
<li>Represent image pixels as vectors (RGB values).</li>
<li>Apply K-means to group similar colors.</li>
<li>Replace pixels by their cluster centers → reduces color space → compression.</li>
</ul>
<pre class="mermaid"><code>%%{init: {'theme': 'default'}}%%
flowchart LR
    A[Original Image] --&gt; B[K-means Clustering]
    B --&gt; C[Compressed Image]</code></pre>
<h3 id="minimal-python-for-color-quantization">Minimal Python for Color Quantization<a class="headerlink" href="#minimal-python-for-color-quantization" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a><span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&quot;path/to/image.jpg&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">)</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a><span class="n">K</span> <span class="o">=</span> <span class="mi">16</span>  <span class="c1"># number of colors</span>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a><span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">K</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">arr</span><span class="p">)</span>
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a><span class="n">palette</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a><span class="n">labels</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">labels_</span>
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a><span class="n">compressed</span> <span class="o">=</span> <span class="n">palette</span><span class="p">[</span><span class="n">labels</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="__span-6-13"><a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a>
</span><span id="__span-6-14"><a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a><span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">compressed</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;compressed_k16.jpg&quot;</span><span class="p">)</span>
</span></code></pre></div>
<hr />
<h1 id="generative-modelling">Generative Modelling<a class="headerlink" href="#generative-modelling" title="Permanent link">&para;</a></h1>
<h2 id="what-is-generative-modelling">What is Generative Modelling?<a class="headerlink" href="#what-is-generative-modelling" title="Permanent link">&para;</a></h2>
<ul>
<li>A <strong>generative model</strong> learns the distribution of the input data.</li>
<li>Once you have a model of input data, you can:</li>
<li>Generate new examples</li>
<li>Perform classification/regression (with small labels)</li>
<li>Anomaly detection</li>
<li>Fill missing data</li>
<li>Examples: Density estimation models, Naïve Bayes, Variational Autoencoders (VAE).</li>
</ul>
<h3 id="python-example-naive-bayes-generative-for-classification">Python Example: Naïve Bayes (generative for classification)<a class="headerlink" href="#python-example-naive-bayes-generative-for-classification" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianNB</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a><span class="n">nb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a><span class="n">y_pred</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span><span id="__span-7-11"><a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy:&quot;</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</span></code></pre></div>
<hr />
<h2 id="generative-adversarial-networks-gans">Generative Adversarial Networks (GANs)<a class="headerlink" href="#generative-adversarial-networks-gans" title="Permanent link">&para;</a></h2>
<ul>
<li>Deep-learning based generative models.</li>
<li>Two components:</li>
<li><strong>Generator (G):</strong> Produces synthetic data from noise.</li>
<li><strong>Discriminator (D):</strong> Distinguishes between real and fake samples.</li>
<li>GANs are trained as a <strong>two-player minimax game</strong>:</li>
</ul>
<p><span class="arithmatex">\(\min_G \max_D V(D,G) = \mathbb{E}_{x\sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z\sim p_z(z)}[\log(1-D(G(z)))]\)</span></p>
<h3 id="intuition-two-player-game">Intuition: Two-Player Game<a class="headerlink" href="#intuition-two-player-game" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Criminal (Generator):</strong> Tries to produce counterfeit money indistinguishable from real money.</li>
<li><strong>Cop (Discriminator):</strong> Tries to detect fake money.</li>
<li>Over iterations, both improve until the generator produces realistic samples.</li>
</ul>
<pre class="mermaid"><code>%%{init: {'theme': 'forest'}}%%
flowchart LR
    Z[Random Noise z] --&gt; G[Generator]
    G --&gt; X_fake[Fake Sample]
    X_real[Real Sample] --&gt; D[Discriminator]
    X_fake --&gt; D
    D --&gt;|Real or Fake| Out[Training Feedback]
    Out --&gt; G</code></pre>
<h3 id="gan-training-algorithm-mini-batch-sgd">GAN Training Algorithm (Mini-batch SGD)<a class="headerlink" href="#gan-training-algorithm-mini-batch-sgd" title="Permanent link">&para;</a></h3>
<ol>
<li>
<p>For k steps:</p>
</li>
<li>
<p>Sample minibatch of $m$ noise vectors $z^{(1)},..,z^{(m)}$.</p>
</li>
<li>Sample minibatch of $m$ real examples $x^{(1)},..,x^{(m)}$.</li>
<li>
<p>Update discriminator $D$ by ascending: $\nabla_\theta \frac{1}{m}\sum_{i=1}^m [\log D(x^{(i)}) + \log(1-D(G(z^{(i)})))]$</p>
</li>
<li>
<p>Update generator $G$ by descending: $\nabla_\theta \frac{1}{m}\sum_{i=1}^m [\log(1-D(G(z^{(i)})))]$</p>
</li>
</ol>
<hr />
<h2 id="gan-sample-iteration-visualization">GAN Sample Iteration (Visualization)<a class="headerlink" href="#gan-sample-iteration-visualization" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Iteration 0:</strong> Generator produces random noise.</li>
<li><strong>Iteration 1000:</strong> Generated samples start to mimic structure of data.</li>
<li><strong>Iteration 2000+:</strong> Generated distribution approximates real data.</li>
</ul>
<pre class="mermaid"><code>%%{init: {'theme': 'neutral'}}%%
sequenceDiagram
    participant Z as Noise z
    participant G as Generator
    participant X_fake as Fake Data
    participant D as Discriminator
    participant Real as Real Data

    Z-&gt;&gt;G: Generate G(z)
    G-&gt;&gt;X_fake: Fake samples
    Real-&gt;&gt;D: Pass real samples
    X_fake-&gt;&gt;D: Pass fake samples
    D-&gt;&gt;G: Gradient feedback</code></pre>
<h3 id="minimal-python-gan-pytorch">Minimal Python GAN (PyTorch)<a class="headerlink" href="#minimal-python-gan-pytorch" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span><span class="o">,</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span><span class="o">,</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">optim</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="k">class</span><span class="w"> </span><span class="nc">Generator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">784</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())</span>
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>
</span><span id="__span-8-11"><a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a><span class="k">class</span><span class="w"> </span><span class="nc">Discriminator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-8-12"><a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="__span-8-13"><a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-8-14"><a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="__span-8-15"><a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
</span><span id="__span-8-16"><a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
</span><span id="__span-8-17"><a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-8-18"><a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a>
</span><span id="__span-8-19"><a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a><span class="n">G</span><span class="p">,</span> <span class="n">D</span> <span class="o">=</span> <span class="n">Generator</span><span class="p">(),</span> <span class="n">Discriminator</span><span class="p">()</span>
</span><span id="__span-8-20"><a id="__codelineno-8-20" name="__codelineno-8-20" href="#__codelineno-8-20"></a><span class="n">optG</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0002</span><span class="p">)</span>
</span><span id="__span-8-21"><a id="__codelineno-8-21" name="__codelineno-8-21" href="#__codelineno-8-21"></a><span class="n">optD</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0002</span><span class="p">)</span>
</span><span id="__span-8-22"><a id="__codelineno-8-22" name="__codelineno-8-22" href="#__codelineno-8-22"></a><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
</span><span id="__span-8-23"><a id="__codelineno-8-23" name="__codelineno-8-23" href="#__codelineno-8-23"></a>
</span><span id="__span-8-24"><a id="__codelineno-8-24" name="__codelineno-8-24" href="#__codelineno-8-24"></a><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
</span><span id="__span-8-25"><a id="__codelineno-8-25" name="__codelineno-8-25" href="#__codelineno-8-25"></a><span class="n">fake</span> <span class="o">=</span> <span class="n">G</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</span><span id="__span-8-26"><a id="__codelineno-8-26" name="__codelineno-8-26" href="#__codelineno-8-26"></a><span class="nb">print</span><span class="p">(</span><span class="n">fake</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># (16, 784)</span>
</span></code></pre></div>
<hr />
<h2 id="conditional-gans-cgans">Conditional GANs (cGANs)<a class="headerlink" href="#conditional-gans-cgans" title="Permanent link">&para;</a></h2>
<ul>
<li>GANs conditioned on additional input $y$ (labels, class, or attributes).</li>
<li>Generator learns mapping $G(z|y)$, Discriminator learns $D(x|y)$.</li>
<li>Example: Generate digit images conditioned on label (0–9).</li>
</ul>
<pre class="mermaid"><code>%%{init: {'theme': 'forest'}}%%
flowchart TB
    subgraph cGAN
    Z[Noise z] --&gt; G["Generator G(z|y)"]
    Y1[Condition y] --&gt; G
    G --&gt; X_fake[Fake Sample]
    X_real[Real Sample] --&gt; D["Discriminator D(x|y)"]
    Y2[Condition y] --&gt; D
    X_fake --&gt; D
    D --&gt; Out[Real/Fake conditioned]
    Out --&gt; G
    end
</code></pre>
<h3 id="pytorch-snippet-for-cgan">PyTorch Snippet for cGAN<a class="headerlink" href="#pytorch-snippet-for-cgan" title="Permanent link">&para;</a></h3>
<div class="language-python highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="k">class</span><span class="w"> </span><span class="nc">CondGenerator</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">,</span> <span class="n">z_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_classes</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">z_dim</span><span class="o">+</span><span class="mi">10</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">784</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">())</span>
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a>        <span class="n">y_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="__span-9-10"><a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">z</span><span class="p">,</span> <span class="n">y_embed</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</span></code></pre></div>
<hr />
<h2 id="applications-of-gans">Applications of GANs<a class="headerlink" href="#applications-of-gans" title="Permanent link">&para;</a></h2>
<p>GANs have been successfully applied to a wide variety of domains:</p>
<ol>
<li>
<p><strong>Super-Resolution</strong></p>
</li>
<li>
<p>Enhancing low-resolution images to high resolution.</p>
</li>
<li>
<p>Example: SRGAN.</p>
</li>
<li>
<p><strong>Connectivity-based</strong></p>
</li>
<li>
<p>Semantic segmentation and label-to-image translation.</p>
</li>
<li>
<p>Example: GauGAN.</p>
</li>
<li>
<p><strong>Graph-based</strong></p>
</li>
<li>
<p>Filling missing regions in images (image inpainting).</p>
</li>
<li>
<p>Example: Context encoders.</p>
</li>
<li>
<p><strong>Distribution-based</strong></p>
</li>
<li>
<p>Style transfer, domain adaptation, aerial-to-map, map-to-aerial transformations.</p>
</li>
<li>
<p><strong>Density-based</strong></p>
</li>
<li>
<p>Face generation, avatar synthesis, human image generation.</p>
</li>
<li>
<p><strong>Others</strong></p>
</li>
<li>
<p>Image editing</p>
</li>
<li>Imitation learning</li>
<li>Music generation</li>
</ol>
<hr />
<h1 id="representation-learning">Representation Learning<a class="headerlink" href="#representation-learning" title="Permanent link">&para;</a></h1>
<p>Representation learning is a set of techniques in machine learning that enables a system to <strong>automatically discover useful representations of raw data</strong>. These representations transform raw inputs into more structured formats that make downstream tasks such as <strong>feature detection, classification, or regression</strong> easier.</p>
<p>Instead of manually engineering features, representation learning techniques automatically identify the right abstractions.</p>
<hr />
<h2 id="types-of-representation-learning">Types of Representation Learning<a class="headerlink" href="#types-of-representation-learning" title="Permanent link">&para;</a></h2>
<ol>
<li><strong>Text Representations</strong></li>
<li>Converts raw text into vectors that encode semantic meaning.</li>
<li>Captures <strong>word similarity</strong>, <strong>syntactic roles</strong>, and <strong>semantic context</strong>.</li>
<li>
<p>Examples:</p>
<ul>
<li><strong>Word2Vec</strong> (continuous representations of words)</li>
<li><strong>BERT</strong> (contextual embeddings)</li>
</ul>
</li>
<li>
<p><strong>Graph Representations</strong></p>
</li>
<li>Encodes nodes and edges into dense vectors.</li>
<li>Preserves structural information such as neighborhood, connectivity, and paths.</li>
<li>
<p>Examples:</p>
<ul>
<li><strong>DeepWalk</strong> (random walks + Skip-gram)</li>
<li><strong>node2vec</strong> (biased random walks for flexible embeddings)</li>
</ul>
</li>
<li>
<p><strong>Image Representations</strong></p>
</li>
<li>Learns features automatically from pixels.</li>
<li><strong>Self-supervised contrastive learning</strong> extracts features without labeled data.</li>
<li>Enables clustering and transfer learning across visual tasks.</li>
</ol>
<pre class="mermaid"><code>flowchart LR
    subgraph Text
      A["Raw Text corpus"] --&gt; B["Tokenizer"]
      B --&gt; C["Context Windows"]
      C --&gt; D["Embedding Model&lt;br&gt;Word2Vec / BERT"]
      D --&gt; E["Downstream Tasks"]
    end
    subgraph Graph
      G1["Graph Data&lt;br&gt;nodes &amp; edges"] --&gt; G2["Random Walks"]
      G2 --&gt; G3["Skip-gram Training"]
      G3 --&gt; G4["Node Embeddings"]
    end
    subgraph Image
      I1["Unlabeled Images"] --&gt; I2["Augmentations"]
      I2 --&gt; I3["Contrastive Objective"]
      I3 --&gt; I4["Image Embeddings"]
    end
</code></pre>
<hr />
<h2 id="distributed-representations">Distributed Representations<a class="headerlink" href="#distributed-representations" title="Permanent link">&para;</a></h2>
<p>A core idea in representation learning is moving from <strong>sparse representations</strong> (e.g., one-hot vectors) to <strong>dense distributed representations</strong> (embeddings).</p>
<ul>
<li><strong>One-hot representation (Sparse)</strong></li>
<li>Each word is represented as a binary vector with a single 1.</li>
<li>Does not capture similarity between words.</li>
<li>
<p>High dimensional and memory inefficient.
  <div class="language-text highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>banana = [0 0 0 0 0 0 0 1 0 0 0]
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>mango  = [0 0 0 0 0 1 0 0 0 0 0]
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>dog    = [0 0 1 0 0 0 0 0 0 0 0]
</span></code></pre></div></p>
</li>
<li>
<p><strong>Distributed representation (Dense)</strong></p>
</li>
<li>Each word is a low-dimensional vector of real numbers.</li>
<li>Similar words have similar vectors.</li>
<li>Captures semantic and syntactic properties.
  <div class="language-text highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a>banana = [0.23  0.1 -0.1 -0.4 -0.01 -0.121 0.342 0.561]
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>mango  = [-0.73 0.0 -0.5  0.4  0.4   0.591 0.732 0.891]
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>dog    = [0.61  0.21 0.55 0.45 0.134 0.752 0.525 0.64 ]
</span></code></pre></div></li>
</ul>
<pre class="mermaid"><code>flowchart LR
    O1[One-hot Vectors\nHigh-dim, sparse] -- limitations --&gt; L1[No similarity\ninfo]
    O1 --&gt; L2[Large memory]
    D1[Dense Embeddings\nLow-dim, real-valued] -- benefits --&gt; B1[Capture similarity]
    D1 --&gt; B2[Generalize across contexts]
    D1 --&gt; B3[Efficient storage]</code></pre>
<hr />
<h2 id="word2vec-word-representations">Word2Vec: Word Representations<a class="headerlink" href="#word2vec-word-representations" title="Permanent link">&para;</a></h2>
<blockquote>
<p><em>“You shall know a word by the company it keeps”</em> – J.R. Firth (1957)</p>
</blockquote>
<p>Word2Vec is a neural model that learns <strong>word embeddings</strong> by leveraging context.</p>
<ul>
<li>A word’s meaning is inferred from its <strong>neighboring words</strong> in a large corpus.</li>
<li>Example:</li>
<li>Target word: <em>banking</em>  </li>
<li>Context words: <code>w_{t-1}, w_{t+1}, ...</code></li>
</ul>
<p>Word2Vec comes in two variants: <strong>CBOW</strong> and <strong>Skip-gram</strong>.</p>
<hr />
<h2 id="basic-idea-of-word2vec">Basic Idea of Word2Vec<a class="headerlink" href="#basic-idea-of-word2vec" title="Permanent link">&para;</a></h2>
<p><strong>Input assumptions:</strong>
- A huge corpus of text <span class="arithmatex">\(C\)</span>
- A pre-defined vocabulary <span class="arithmatex">\(V\)</span></p>
<p><strong>Representation:</strong>
- Each word has two vectors:
  - <span class="arithmatex">\( v_{w_t} \)</span>: word as a <strong>target</strong>
  - <span class="arithmatex">\( v_{w_c} \)</span>: word as a <strong>context</strong></p>
<h3 id="models">Models<a class="headerlink" href="#models" title="Permanent link">&para;</a></h3>
<ol>
<li><strong>Continuous Bag of Words (CBOW)</strong></li>
<li>Predicts the <strong>target word</strong> given surrounding context words.</li>
<li>
<p>Uses softmax over similarity between the target vector and the <strong>sum of context vectors</strong>.</p>
</li>
<li>
<p><strong>Skip-gram (SG)</strong></p>
</li>
<li>Predicts the <strong>context words</strong> given a target word.</li>
<li>Uses softmax over similarity between target and context vectors.</li>
</ol>
<pre class="mermaid"><code>flowchart LR
    subgraph CBOW
        w1(("w_{t-2}")) --&gt; SUM(("Σ"))
        w2(("w_{t-1}")) --&gt; SUM
        w3(("w_{t+1}")) --&gt; SUM
        w4(("w_{t+2}")) --&gt; SUM
        SUM --&gt; target(("w_t"))
    end

    subgraph SkipGram
        target2(("w_t")) --&gt; c1(("w_{t-2}"))
        target2 --&gt; c2(("w_{t-1}"))
        target2 --&gt; c3(("w_{t+1}"))
        target2 --&gt; c4(("w_{t+2}"))
    end
</code></pre>
<hr />
<h2 id="skip-gram-with-window">Skip-gram with Window<a class="headerlink" href="#skip-gram-with-window" title="Permanent link">&para;</a></h2>
<p>Skip-gram works by predicting context words within a fixed <strong>window size</strong> around the target word.</p>
<p>For example, with a window size of 2:</p>
<div class="arithmatex">\[
P(w_{t-2} | w_t), P(w_{t-1} | w_t), P(w_{t+1} | w_t), P(w_{t+2} | w_t)
\]</div>
<pre class="mermaid"><code>flowchart LR
    T(("banking&lt;br&gt;w_t")) --&gt; L1(("problems&lt;br&gt;w_{t-2}"))
    T --&gt; L2(("turning&lt;br&gt;w_{t-1}"))
    T --&gt; R1(("crises&lt;br&gt;w_{t+1}"))
    T --&gt; R2(("as&lt;br&gt;w_{t+2}"))

    classDef ctx fill:#fff,stroke:#999,stroke-width:1px;
    class L1,L2,R1,R2 ctx;
</code></pre>
<p>This ensures both <strong>left</strong> and <strong>right</strong> contexts contribute to training.</p>
<hr />
<h2 id="skip-gram-objective-function">Skip-gram Objective Function<a class="headerlink" href="#skip-gram-objective-function" title="Permanent link">&para;</a></h2>
<p>The optimization goal is:</p>
<div class="arithmatex">\[
\theta^* = \arg\max_{\theta} \prod_{i=1}^{T} \prod_{-m \leq j \leq m, j \neq 0} P(w_{i+j} | w_i; \theta)
\]</div>
<p>Equivalent minimization:</p>
<div class="arithmatex">\[
\theta^* = \arg\min_{\theta} -\frac{1}{T}\sum_{i=1}^T \sum_{-m \leq j \leq m, j \neq 0} \log P(w_{i+j} | w_i; \theta)
\]</div>
<p>Where probability is defined as:</p>
<div class="arithmatex">\[
P(w_{i+j} | w_i) = \frac{\exp(v_{w_i}^T v_{w_{i+j}})}{\sum_{w \in V} \exp(v_{w_i}^T v_{w_c})}
\]</div>
<ul>
<li><strong>Similarity:</strong> computed as dot product of target and context vectors.</li>
<li><strong>Normalization:</strong> softmax ensures probabilities sum to 1 over the entire vocabulary.</li>
</ul>
<pre class="mermaid"><code>flowchart TB
    subgraph "Training Step"
        A["Target word&lt;br&gt;v_{w_t}"] --&gt; D["Dot Product"]
        C["Context word&lt;br&gt;v_{w_c}"] --&gt; D
        D --&gt; S["Score"]
        S --&gt; SM["Softmax /&lt;br&gt;Neg. Sampling"]
        SM --&gt; L["Loss"]
        L --&gt;|backprop| A
        L --&gt;|backprop| C
    end
</code></pre>
<hr />
<h2 id="word2vec-properties">Word2Vec Properties<a class="headerlink" href="#word2vec-properties" title="Permanent link">&para;</a></h2>
<ul>
<li>Embeddings place <strong>similar words close</strong> in vector space.</li>
<li>Captures rich <strong>semantic relationships</strong>, for example:</li>
<li><strong>Gender relationship:</strong> <code>king - man + woman ≈ queen</code></li>
<li><strong>Verb tense:</strong> <code>walked - walking ≈ swam - swimming</code></li>
<li><strong>Geographical relation:</strong> <code>Paris - France ≈ Berlin - Germany</code></li>
</ul>
<pre class="mermaid"><code>flowchart LR
    K[king] --- M[man]
    Q[queen] --- W[woman]
    subgraph Analogies
      direction LR
      K --&gt;| - man + woman | Q
    end
    subgraph Tense
      direction LR
      Walked[walked] --&gt;| - walking | Delta1[Δ]
      Swam[swam] --&gt;| - swimming | Delta2[Δ]
      Delta1 --- Delta2
    end
    subgraph Capitals
      direction LR
      France --- Paris
      Germany --- Berlin
      France --&gt;|offset ≈| Germany
      Paris --&gt;|offset ≈| Berlin
    end</code></pre>
<p>These relationships emerge naturally without explicit supervision.</p>
<hr />
<h2 id="negative-sampling">Negative Sampling<a class="headerlink" href="#negative-sampling" title="Permanent link">&para;</a></h2>
<p>A challenge in Word2Vec is that the <strong>softmax denominator</strong> involves summing over the entire vocabulary, which is computationally expensive for large vocabularies.</p>
<p><strong>Solution: Negative Sampling (a form of NCE)</strong>
- Instead of updating all weights, only update a few sampled negative examples at each step.
- The model learns to discriminate between:
  - Positive (real context) pairs
  - Negative (random noise) pairs</p>
<p>New simplified objective:</p>
<div class="arithmatex">\[
\log \sigma(v_{w_t}^T v_{w_{c}}) + \sum_{l=1}^k \mathbb{E}_{w_l \sim P_n(w)} [\log \sigma(-v_{w_t}^T v_{w_l})]
\]</div>
<p>Where the <strong>noise distribution</strong> is:</p>
<div class="arithmatex">\[
P_n(w) \propto U(w)^{3/4}
\]</div>
<pre class="mermaid"><code>flowchart LR
    subgraph Sampling
      T(("Target&lt;br&gt;w_t")) --&gt; P1(("Pos Context&lt;br&gt;w_c"))
      T --&gt; N1(("Neg 1"))
      T --&gt; N2(("Neg 2"))
      T --&gt; Nk(("Neg k"))
    end

    P1 --&gt; L1["log σ(v_t^T v_c)"]
    N1 --&gt; L2["log σ(-v_t^T v_{n1})"]
    N2 --&gt; L3["log σ(-v_t^T v_{n2})"]
    Nk --&gt; Lk["log σ(-v_t^T v_{nk})"]

    L1 --&gt; SUM(("Sum Loss"))
    L2 --&gt; SUM
    L3 --&gt; SUM
    Lk --&gt; SUM
</code></pre>
<p>This reduces training complexity while preserving embedding quality.</p>
<hr />
<h2 id="how-deepwalk-node2vec-connect-to-skip-gram">How DeepWalk / node2vec Connect to Skip-gram<a class="headerlink" href="#how-deepwalk-node2vec-connect-to-skip-gram" title="Permanent link">&para;</a></h2>
<p>Both methods generate <strong>node sequences</strong> via random walks and then train a Skip-gram model on those sequences—treating walks like sentences.</p>
<pre class="mermaid"><code>flowchart LR
    G[Graph] --&gt; RW["Random Walks&lt;br&gt;(sequences of nodes)"]
    RW --&gt; SG["Skip-gram Training"]
    SG --&gt; Z["Node Embeddings"]

    style G stroke-width:2px
</code></pre>
<hr />
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h2>
<ul>
<li>Representation learning eliminates the need for manual feature engineering.</li>
<li>Dense embeddings capture <strong>semantic, syntactic, and relational properties</strong> of data.</li>
<li>Word2Vec is a landmark method for learning text representations using CBOW and Skip-gram.</li>
<li>Techniques like <strong>negative sampling</strong> make large-scale training feasible.</li>
<li>Graph and image modalities use analogous pipelines to learn meaningful embeddings without heavy labeling.</li>
</ul>
<p>Representation learning underpins many modern AI systems, from NLP to computer vision and graph learning.</p>
<hr />
<h1 id="advanced-topics-in-representation-learning">Advanced Topics in Representation Learning<a class="headerlink" href="#advanced-topics-in-representation-learning" title="Permanent link">&para;</a></h1>
<h2 id="contextual-word-embeddings">Contextual Word Embeddings<a class="headerlink" href="#contextual-word-embeddings" title="Permanent link">&para;</a></h2>
<p>Traditional embeddings like Word2Vec assign a <strong>single vector per word</strong>, regardless of context. However, the same word can mean different things in different contexts:</p>
<ul>
<li><em>open a </em><em>bank</em><em> account</em></li>
<li><em>on the river </em><em>bank</em>**</li>
</ul>
<p>This motivates <strong>contextual embeddings</strong>, which adapt to surrounding words.</p>
<hr />
<h2 id="elmo-embeddings-from-language-models">ELMo (Embeddings from Language Models)<a class="headerlink" href="#elmo-embeddings-from-language-models" title="Permanent link">&para;</a></h2>
<ul>
<li>ELMo uses a <strong>2-layer bidirectional LSTM</strong> (biLM) trained as a language model.</li>
<li>Unlike Word2Vec, which gives static embeddings, <strong>ELMo embeddings are dynamic</strong> and depend on the entire sentence context.</li>
<li>Produces better representations for polysemous words.</li>
</ul>
<p><strong>Training Objective:</strong></p>
<div class="arithmatex">\[
\sum_{k=1}^{N} \Big( \log p(t_k | t_1, …, t_{k-1}; \theta_{LSTM}^{→}) + \log p(t_k | t_{k+1}, …, t_N; \theta_{LSTM}^{←}) \Big)
\]</div>
<pre class="mermaid"><code>flowchart TB
    E1[Input E1] --&gt; L1[LSTM Forward]
    E2[Input E2] --&gt; L1
    E3[Input E3] --&gt; L1
    E1 --&gt; L2[LSTM Backward]
    E2 --&gt; L2
    E3 --&gt; L2
    L1 --&gt; O1[Contextual Embeddings]
    L2 --&gt; O1</code></pre>
<hr />
<h2 id="bert-bidirectional-encoder-representations-from-transformers">BERT (Bidirectional Encoder Representations from Transformers)<a class="headerlink" href="#bert-bidirectional-encoder-representations-from-transformers" title="Permanent link">&para;</a></h2>
<ul>
<li>Uses the <strong>Transformer architecture</strong> with multi-head self-attention.</li>
<li>Generates <strong>bidirectional contextual embeddings</strong>, allowing words to "see" both left and right contexts simultaneously.</li>
<li>Pretrained on two tasks:</li>
<li><strong>Masked Language Modeling (MLM)</strong>: randomly mask tokens and predict them.</li>
<li><strong>Next Sentence Prediction (NSP)</strong>: predict if sentence B follows sentence A.</li>
</ul>
<p><strong>Advantages:</strong>
- Deep bidirectional attention captures richer context than LSTMs.
- Strong transfer learning: pretrained weights can be fine-tuned on many downstream NLP tasks.</p>
<pre class="mermaid"><code>flowchart TB
    subgraph BERT Pretraining
      direction TB
      A[Input Tokens] --&gt; M1[Masked Tokens]
      M1 --&gt; T[Transformer Layers]
      T --&gt; MLM[Masked LM Prediction]
      A2[Sentence A] --&gt; T
      B2[Sentence B] --&gt; T
      T --&gt; NSP[Next Sentence Prediction]
    end</code></pre>
<hr />
<h2 id="bert-pretraining-tasks">BERT Pretraining Tasks<a class="headerlink" href="#bert-pretraining-tasks" title="Permanent link">&para;</a></h2>
<ol>
<li><strong>Masked Language Model (MLM):</strong></li>
<li>Randomly mask 15% of tokens.</li>
<li>Of these: 80% replaced with [MASK], 10% replaced with random tokens, 10% unchanged.</li>
<li>
<p>Example:</p>
<ul>
<li>Input: <em>the man went to the [MASK] to buy a [MASK] of milk</em></li>
<li>Predictions: <code>store</code>, <code>gallon</code></li>
</ul>
</li>
<li>
<p><strong>Next Sentence Prediction (NSP):</strong></p>
</li>
<li>Sentence A: <em>The man went to the store.</em></li>
<li>Sentence B: <em>He bought a gallon of milk.</em> → Label = IsNextSentence</li>
<li>Sentence B: <em>Penguins are flightless.</em> → Label = NotNextSentence</li>
</ol>
<hr />
<h2 id="graph-embeddings-why">Graph Embeddings – Why?<a class="headerlink" href="#graph-embeddings-why" title="Permanent link">&para;</a></h2>
<p>Graph data is ubiquitous:
- <strong>Knowledge Graphs</strong> (search engines, question answering)
- <strong>Social Graphs</strong> (friend/follow recommendations)
- <strong>Recommendation Systems</strong> (products, items, users)</p>
<pre class="mermaid"><code>flowchart LR
    A((Alice)) --&gt;|visits| B((Paris))
    A --&gt;|is interested in| C((Mona Lisa))
    C --&gt;|is created by| D((Leonardo da Vinci))</code></pre>
<hr />
<h2 id="graph-basics">Graph Basics<a class="headerlink" href="#graph-basics" title="Permanent link">&para;</a></h2>
<p>A graph is defined as:</p>
<p>[
G = (V, E)
]
- <span class="arithmatex">\( V \)</span>: set of vertices (nodes)
- <span class="arithmatex">\( E \subset V \times V \)</span>: edges (connections)</p>
<p><strong>Modalities:</strong>
- Node embeddings
- Edge embeddings
- Subgraph embeddings
- Whole-graph embeddings</p>
<p>Goal: learn embeddings that preserve <strong>graph structure</strong> while being useful for downstream tasks.</p>
<hr />
<h2 id="deepwalk">DeepWalk<a class="headerlink" href="#deepwalk" title="Permanent link">&para;</a></h2>
<ul>
<li>Generates random walks on the graph.</li>
<li>Treats walks as sentences and applies <strong>Skip-gram</strong> for training node embeddings.</li>
<li>Preserves both local and global graph structures.</li>
</ul>
<pre class="mermaid"><code>flowchart LR
    subgraph DeepWalk
      N1((v1)) --&gt; N2((v5)) --&gt; N3((v7)) --&gt; N4((v2))
    end
    DeepWalk --&gt; SG[Skip-gram Training]
    SG --&gt; Emb[Node Embeddings]</code></pre>
<p><strong>Algorithm (simplified):</strong>
1. Perform multiple random walks per node.
2. Train Skip-gram on sequences of visited nodes.
3. Output low-dimensional node embeddings.</p>
<hr />
<h2 id="node2vec">Node2Vec<a class="headerlink" href="#node2vec" title="Permanent link">&para;</a></h2>
<p>Node2Vec extends DeepWalk with a flexible <strong>biased random walk strategy</strong>:
- Parameters:
  - <span class="arithmatex">\(p\)</span>: return parameter (exploration vs revisiting)
  - <span class="arithmatex">\(q\)</span>: in-out parameter (BFS vs DFS bias)</p>
<ul>
<li>If <span class="arithmatex">\(p &gt; 1 &gt; q\)</span>: encourages <strong>global exploration</strong>.</li>
<li>If <span class="arithmatex">\(p &lt; 1 &lt; q\)</span>: encourages <strong>local exploration</strong>.</li>
</ul>
<pre class="mermaid"><code>flowchart LR
    U((u)) --&gt;|BFS| S1((s1))
    U --&gt;|BFS| S2((s2))
    U --&gt;|DFS| S3((s3))
    U --&gt;|DFS| S4((s4))</code></pre>
<hr />
<h2 id="node2vec-community-vs-structural-roles">Node2Vec Community vs Structural Roles<a class="headerlink" href="#node2vec-community-vs-structural-roles" title="Permanent link">&para;</a></h2>
<ul>
<li>By tuning <span class="arithmatex">\(p, q\)</span>, Node2Vec can:</li>
<li>Capture <strong>community structure</strong> (nodes in the same cluster).</li>
<li>Capture <strong>structural equivalence</strong> (nodes with similar roles, even in different communities).</li>
</ul>
<pre class="mermaid"><code>flowchart TB
    subgraph Community Structure
      A1((Node A)) --- A2((Node B)) --- A3((Node C))
      A2 --- A4((Node D))
    end
    subgraph Structural Equivalence
      B1((Hub 1)) --- X((Peripheral))
      B2((Hub 2)) --- X
    end</code></pre>
<hr />
<h1 id="image-representations">Image Representations<a class="headerlink" href="#image-representations" title="Permanent link">&para;</a></h1>
<h2 id="contrastive-learning">Contrastive Learning<a class="headerlink" href="#contrastive-learning" title="Permanent link">&para;</a></h2>
<ul>
<li>Goal: learn an embedding space where <strong>similar pairs are close</strong> and <strong>dissimilar pairs are far apart</strong>.</li>
<li>Given anchor <span class="arithmatex">\(x\)</span>, positive <span class="arithmatex">\(x^+\)</span>, and negative <span class="arithmatex">\(x^-\)</span>:</li>
</ul>
<p><strong>Contrastive Loss:</strong>
 <span class="arithmatex">\(\lVert x - x^+ \rVert^2 + \max(0, m - \lVert x - x^- \rVert^2)\)</span></p>
<p><strong>Triplet Loss:</strong>
<span class="arithmatex">\(\max(0, \lVert x - x^+ \rVert^2 - \lVert x - x^- \rVert^2 + m)\)</span></p>
<pre class="mermaid"><code>flowchart LR
    A[Anchor x] --&gt; P[Positive x⁺]
    A --&gt; N[Negative x⁻]
    P --&gt;|close in embedding| Z[Embedding Space]
    N --&gt;|far apart| Z</code></pre>
<hr />
<h2 id="simclr-simple-framework-for-contrastive-learning-of-representations">SimCLR (Simple Framework for Contrastive Learning of Representations)<a class="headerlink" href="#simclr-simple-framework-for-contrastive-learning-of-representations" title="Permanent link">&para;</a></h2>
<ul>
<li>Framework for <strong>self-supervised learning (SSL)</strong> with contrastive loss.</li>
<li>Given <span class="arithmatex">\(n\)</span> images, generate <span class="arithmatex">\(2n\)</span> augmented samples.</li>
<li>For each positive pair, there are <span class="arithmatex">\(2(n-1)\)</span> negative pairs.</li>
</ul>
<p><strong>NT-Xent (Normalized Temperature-scaled Cross Entropy) Loss:</strong>
<span class="arithmatex">\(<span class="arithmatex">\(\mathcal{L}_{i,j} = - \log \frac{\exp(\text{sim}(z_i, z_j)/\tau)}{\sum_{k=1}^{2n} 1_{[k \neq i]} \exp(\text{sim}(z_i, z_k)/\tau)}\)</span>\)</span></p>
<ul>
<li>Key idea: maximize agreement between positive pairs.</li>
<li>Uses strong <strong>data augmentations</strong> (cropping, flipping, color distortion, Gaussian blur, etc.).</li>
</ul>
<pre class="mermaid"><code>flowchart TB
    X["Input Image"] --&gt; Aug1["Augmentation t"]
    X --&gt; Aug2["Augmentation t'"]
    Aug1 --&gt; F1["Encoder f(·)"] --&gt; H1["Projection Head h(·)"] --&gt; Z1["Embedding z_i"]
    Aug2 --&gt; F2["Encoder f(·)"] --&gt; H2["Projection Head h(·)"] --&gt; Z2["Embedding z_j"]
    Z1 --&gt; Loss["Contrastive Loss"]
    Z2 --&gt; Loss
</code></pre>
<p><strong>Impact:</strong>
- Achieved <strong>state-of-the-art in SSL</strong>, surpassing supervised ResNet-50 on ImageNet Top-1 accuracy.</p>
<hr />
<h1 id="summary-of-advanced-topics">Summary of Advanced Topics<a class="headerlink" href="#summary-of-advanced-topics" title="Permanent link">&para;</a></h1>
<ul>
<li><strong>ELMo</strong>: Contextual embeddings using BiLSTM.</li>
<li><strong>BERT</strong>: Transformer-based contextual embeddings with MLM and NSP.</li>
<li><strong>Graph embeddings</strong>: Learn node/edge/subgraph representations preserving structure.</li>
<li><strong>DeepWalk</strong>: Uses random walks + Skip-gram.</li>
<li><strong>Node2Vec</strong>: Extends DeepWalk with biased random walks for better control of context.</li>
<li><strong>Contrastive Learning &amp; SimCLR</strong>: Powerful SSL methods for images, learning embeddings without labels.</li>
</ul>
<p>These advances form the foundation of <strong>modern NLP, graph, and image representation learning</strong>.</p>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="August 17, 2025 08:29:46 UTC">August 17, 2025</span>
  </span>

    
    
    
    
  </aside>





                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../lecture3/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Dimensionality Reduction">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Dimensionality Reduction
              </div>
            </div>
          </a>
        
        
          
          <a href="../../cheatsheets/" class="md-footer__link md-footer__link--next" aria-label="Next: Cheatsheets">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Cheatsheets
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/adityachauhan0" target="_blank" rel="noopener" title="GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.instant", "navigation.tracking", "navigation.indexes", "navigation.sections", "navigation.tabs", "navigation.top", "navigation.footer", "toc.integrate", "toc.follow", "search.suggest", "search.highlight", "search.share", "content.code.copy", "content.code.annotate", "content.tooltips", "header.autohide", "content.action.edit", "content.action.view"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.92b07e13.min.js"></script>
      
        <script src="https://unpkg.com/mermaid@10/dist/mermaid.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
      
        <script src="../../js/katex-init.js"></script>
      
    
  </body>
</html>